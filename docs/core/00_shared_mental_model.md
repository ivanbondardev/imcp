# Shared Mental Model  
## IMCP — Iron Man Case Platform

**Версія:** 1.1  
**Статус:** Core / Foundational  
**Тип документа:** Concept (не контракт, а модель мислення)  
**Аудиторія:** Product, Architecture, Engineering, Operations, Leadership  
**Призначення:** Єдина узгоджена модель мислення для всієї платформи

**Наступні документи (контракти):**  
- [01_architecture_overview.md](./01_architecture_overview.md) — архітектура та межі компонентів  
- [02_core_data_model.md](./02_core_data_model.md) — модель даних (специфікація)  
- [03_approval_pattern.md](./03_approval_pattern.md) — патерн підтверджень  
- [04_case_cockpit_ux.md](./04_case_cockpit_ux.md) — UX/UI патерни  
- [05_platform_checklist.md](./05_platform_checklist.md) — чекліст відповідності принципам

---

## 1. Purpose — Навіщо існує цей документ

Цей документ фіксує **єдину спільну модель мислення (Shared Mental Model)** щодо того,  
як ми проєктуємо, будуємо і розвиваємо платформу **Iron Man Suit**.

Він відповідає не на питання *“як реалізовано”*, а на питання:

> **“Як ми думаємо про систему, ролі людини та ШІ, процеси й відповідальність?”**

Цей документ є:
- якірним артефактом для всієї платформи;
- фільтром для архітектурних і продуктових рішень;
- основою для PoC, MVP та масштабування;
- onboarding-документом для нових учасників команди.

---

## 2. Core Idea — Концепція IMCP

**IMCP (Iron Man Case Platform)** — це підхід до створення систем часткової автономії,  
де **ШІ підсилює людину, але не замінює її відповідальність**.

### Ключова метафора
- **Людина — пілот**
- **ШІ — екзоскелет / Jarvis**
- **Система — костюм, а не автопілот**

ШІ:
- пришвидшує аналіз,
- знімає рутину,
- пропонує варіанти,
- контролює повноту і помилки.

Людина:
- верифікує,
- приймає фінальні рішення,
- несе відповідальність,
- застосовує контекст і досвід.

> Без людини костюм — це просто метал.  
> Без костюма людина повільна і перевантажена.  
> Разом — вони працюють у рази ефективніше.

---

## 3. Division of Responsibilities — Розподіл обовʼязків

### ШІ відповідає за:
- генерацію варіантів рішень;
- аналіз великих обсягів даних;
- підготовку чернеток документів (draft-first);
- виявлення прогалин, аномалій і суперечностей;
- дотримання формальних правил і чеклістів;
- таймінги, нагадування, тригери.

### Людина відповідає за:
- верифікацію результатів ШІ;
- фінальне підтвердження дій;
- контекстуальні та нестандартні рішення;
- відповідальність за незворотні операції;
- взаємодію з клієнтами та партнерами.

> **Принцип:**  
> ШІ ніколи не має права самостійно виконувати незворотні або високоризикові дії.

---

## 4. Processes as Graphs, not Checklists

Ми розглядаємо логістику (і будь-який інший складний домен)  
не як список інструкцій, а як **граф станів (state machine)**.

### Ключова термінологія

> Див. детальну специфікацію в [02_core_data_model.md](./02_core_data_model.md#2-термінологія-state-vs-status)

| Термін | Що означає |
|--------|------------|
| **State** | Бізнес-стан у state machine (напр. `WAITING_CLIENT_INFO`) |
| **Status** | Технічний агрегат (`OPEN`, `BLOCKED`, `DONE`) |

### Основні принципи:
- Процес = набір **станів (states)**, а не кроків
- Кожен стан має вхідні дані, умови переходу, потенційні ризики
- Перехід між станами — це **подія (event)**
- Паралельні процеси = **substates** (не замість, а разом з primary state)

Такий підхід:
- краще масштабується
- дозволяє обробляти винятки
- напряму мапиться на workflow engines (n8n)
- робить процес прозорим для людини

---

## 5. Automation ≠ Autonomy

Один із фундаментальних принципів платформи:

> **Автоматизація не означає автономність.**

### Ми чітко розрізняємо:
- **Автоматичні дії**  
  (підготовка, запуск наступного кроку, збір даних)
- **Автономні рішення**  
  (фінанси, юридичні дії, скасування, підтвердження)

### Незворотні дії завжди потребують:
- явного підтвердження людини;
- фіксації: хто, коли і що підтвердив.

### Autonomy Slider (Адаптивна автономія)
Ми мислимо автономію як **повзунок**, а не як бінарний стан:
- ШІ може пропонувати;
- ШІ може виконувати в межах дозволів;
- Людина визначає межі автономії в кожному кейсі.

### Режими нагляду (HOTL ↔ HITL)

| Режим | Опис | Коли застосовується |
|-------|------|---------------------|
| **HOTL** (Human-on-the-Loop) | Людина спостерігає, система діє автономно | Рутинні операції, високий confidence |
| **HITL** (Human-in-the-Loop) | Людина безпосередньо контролює | Нові контексти, низький confidence, високий ризик |

### Автоматичне переключення режимів:

Система **самостійно переходить** з HOTL у HITL при:
- падінні confidence нижче порогу
- виявленні нового/невідомого контексту
- серії помилок або відхилень
- досягненні ліміту автономних дій

> **Принцип:** Рівень автономії залежить від контексту і може динамічно змінюватись.

---

## 6. Human Knowledge as a First-Class Asset

Досвід менеджерів — це **не шум**, а ключова цінність.

### Ми визнаємо, що:
- багато рішень базуються на неявних знаннях;
- ці знання не формалізовані в правилах;
- вони накопичуються роками практики.

### Роль платформи:
- зберігати історію рішень;
- аналізувати патерни підтверджень і відхилень;
- використовувати їх для кращих пропозицій у майбутньому.

> Кожне підтвердження людини — це навчальний сигнал для системи.

---

## 6.1 HITL 2.0 — Взаємне навчання (Learning Loop)

IMCP реалізує **двосторонній цикл навчання** між людиною та системою:

```
┌─────────────────────────────────────────────────────────┐
│                  LEARNING LOOP                          │
│                                                         │
│  ┌─────────┐    generates    ┌──────────┐              │
│  │   AI    │ ───────────────► │  Draft   │              │
│  └─────────┘                  └────┬─────┘              │
│       ▲                            │                    │
│       │                            ▼                    │
│       │ improves           ┌──────────────┐            │
│       │ over time          │    Human     │            │
│       │                    │   verifies   │            │
│       │                    └──────┬───────┘            │
│       │                           │                    │
│       │    ┌──────────────────────┼───────────────┐    │
│       │    │                      ▼               │    │
│       │    │    ┌─────────────────────────────┐   │    │
│       │    │    │  Correction Signal          │   │    │
│       │    │    │  • what was changed         │   │    │
│       │    │    │  • why (correction_type)    │   │    │
│       │    │    │  • confidence delta         │   │    │
│       └────┼────│                             │   │    │
│            │    └─────────────────────────────┘   │    │
│            │              QUALITY                 │    │
│            │               LOOP                   │    │
│            └──────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────┘
```

### Ключові принципи HITL 2.0:

| Аспект | Традиційний HITL | HITL 2.0 (IMCP) |
|--------|------------------|-----------------|
| Роль людини | Виправляє помилки | Навчає систему |
| Тип зворотного зв'язку | "Так/Ні" | Структуровані корекції |
| Результат виправлень | Одноразова дія | Сигнал для покращення |
| Прозорість AI | "Чорна скринька" | Пояснення reasoning |
| Довгострокова мета | Контроль | Зменшення помилок з часом |

### Як це працює в IMCP:

1. **AI показує reasoning** — не тільки результат, а й "чому так вирішено"
2. **Людина коригує з контекстом** — не просто "відхилити", а "чому відхилено"
3. **Корекції структуруються** — `correction_type`, `edited_fields`, `delta`
4. **Система аналізує патерни** — де частіше помиляється, які поля потребують уваги
5. **Якість покращується** — менше помилок → менше втручань → швидша робота

> **HITL 2.0 = людина не просто "запобіжник", а "вчитель" для системи.**

---

## 7. Fatigue-Aware Design — Проєктування з урахуванням утоми

Ми виходимо з того, що:
- помилки виникають не через некомпетентність;
- а через перевантаження та монотонність.

### Найбільш ризикові зони:
- перевірка документів;
- дедлайни;
- повторювані операції;
- "ще один кейс наприкінці дня".

ШІ має:
- знімати когнітивне навантаження;
- підсвічувати важливе;
- не вимагати постійної уваги.

---

## 7.1 Подолання когнітивних пасток

Символічний контроль часто провалюється через когнітивні пастки. IMCP має активно їм протидіяти.

### Основні пастки та їх вирішення:

| Пастка | Опис | Як IMCP протидіє |
|--------|------|-----------------|
| **Automation Bias** | Надмірна довіра до автоматизованих рішень | Прозорість невпевненості, spot checks |
| **Complacency** | Втрата пильності при частих правильних результатах | Режим "Verify Mode", активні перевірки |
| **Confirmation Bias** | Пошук підтвердження, а не спростування | Парадигма "довести, що AI помиляється" |
| **Approval Fatigue** | Втома від великої кількості схвалень | Інтелектуальні точки зупинки, пріоритезація |

### Механізми протидії:

#### 1. Прозорість невпевненості
- UI **завжди показує** рівень впевненості AI (confidence)
- Суперечності та конфлікти **підсвічуються**, а не приховуються
- AI не маскує невпевненість "авторитетним тоном"

#### 2. Парадигма спростування
- Замість питання "Чи AI правий?" ставимо "Де AI міг помилитись?"
- Для критичних approvals система пропонує перевірити конкретні поля
- Чеклісти верифікації для високоризикових операцій

#### 3. Spot Checks (активні перевірки)
- Періодично система вимагає **розгорнуту верифікацію** навіть для "очевидних" рішень
- Ротація типів перевірок для підтримки пильності
- Метрики "глибини перегляду" для кожного менеджера

#### 4. Інтелектуальні точки зупинки
- **Не всі дії потребують approval** — це би створило fatigue
- Система **автоматично класифікує** операції за ризиком
- Обов'язкові паузи тільки для критичних/незворотних дій

### Класифікація операцій за ризиком:

| Рівень ризику | Приклади | Поведінка системи |
|---------------|----------|-------------------|
| **LOW** | Читання даних, нотифікації | Автоматично, без approval |
| **MEDIUM** | Зміна полів, генерація чернеток | Approval за умови anomalies |
| **HIGH** | Фінансові операції, юридичні дії | Обов'язковий approval |
| **CRITICAL** | Незворотні дії в зовнішніх системах | Approval + confirmation step |

> **Принцип:** Вибіркове втручання замість тотального контролю.

---

## 8. Interfaces over Chatbots

Ми **не будуємо чат-ботів для управління складними процесами**.

### Наш UX-принцип:
**Single Pane of Glass**

Менеджер повинен бачити:
- стан кейса;
- ключові дані;
- ризики;
- пропозиції ШІ;
- доступні дії.

### Основна форма взаємодії:
- структуровані чернетки;
- кнопки “підтвердити / змінити / відхилити”;
- мінімум вільного тексту;
- максимум контрольованих дій.

---

## 9. Accountability & Auditability

Будь-яка критична дія в системі має бути:
- відтворювана;
- пояснювана;
- привʼязана до конкретної людини.

### Ми завжди знаємо:
- хто підтвердив рішення;
- на основі яких даних;
- в який момент часу;
- з якою версією інформації.

Це основа довіри до системи.

---

## 10. Metrics that Matter

Ми оцінюємо систему не за “кількістю автоматизацій”, а за:

- швидкістю прийняття рішень;
- кількістю виправлень після ШІ;
- зменшенням помилок;
- стабільністю процесів;
- субʼєктивним відчуттям контролю менеджера;
- якістю сервісу для клієнта.

---

## 11. Transferability — Поза логістикою

Цей mental model **не привʼязаний до логістики**.

Ті самі принципи застосовні до:
- фінансів;
- legal;
- procurement;
- compliance;
- operations.

Змінюється **кейс**, а не **платформа**.

---

## 11.1 Балансування чотирьох сил HITL-архітектури

Ефективна система управління ризиками агентного ШІ балансує **чотири конкуруючі сили**:

```
                        ┌─────────────────┐
                        │     ДОВІРА      │
                        │   (Trust)       │
                        │                 │
                        │ "Не вгадувати   │
                        │  в критичних    │
                        │  ситуаціях"     │
                        └────────┬────────┘
                                 │
         ┌───────────────────────┼───────────────────────┐
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   ШВИДКІСТЬ     │    │    БАЛАНС       │    │  ПОВНОВАЖЕННЯ   │
│   (Speed)       │◄───│                 │───►│  (Authority)    │
│                 │    │   IMCP Design   │    │                 │
│ "Не блокувати   │    │    Goal         │    │ "Тільки         │
│  low-risk"      │    │                 │    │  авторизовані"  │
└─────────────────┘    └────────┬────────┘    └─────────────────┘
                                │
                                ▼
                        ┌─────────────────┐
                        │   ВАРТІСТЬ      │
                        │   (Cost)        │
                        │                 │
                        │ "Людський час — │
                        │  дорогий ресурс"│
                        └─────────────────┘
```

### Як IMCP балансує ці сили:

| Сила | Принцип IMCP | Механізм реалізації |
|------|--------------|---------------------|
| **Довіра** | AI не діє автономно при високих ставках | Класифікація ризику (HIGH/CRITICAL → approval), прозорість uncertainty |
| **Швидкість** | Low-risk операції не блокуються | HOTL режим, auto-execute для LOW-risk, LLM-as-Critic фільтрація |
| **Вартість** | Людина втручається тільки там, де це має сенс | Intelligent breakpoints, Learning Loop (з часом менше помилок → менше втручань) |
| **Повноваження** | Тільки авторизовані особи схвалюють | RLS, `approval_permissions`, role-based access |

### Ознаки дисбалансу:

| Симптом | Що порушено | Як виправити |
|---------|-------------|--------------|
| "Rubber stamping" — формальні галочки | Занадто багато approvals (Speed/Cost) | Підняти пороги, додати LLM-critic |
| Помилки в production | Недостатня довіра (Trust) | Додати approval gates, знизити autonomy |
| Менеджери перевантажені | Порушено Cost | Оптимізувати UX, автоматизувати LOW-risk |
| Неавторизовані схвалення | Порушено Authority | Посилити RLS, аудит |
| Затримки в критичних операціях | Порушено Speed | Паралельні approvals, async workflows |

### Метрики балансу:

| Метрика | Що вимірює | Target |
|---------|------------|--------|
| `approval_volume_per_user_per_day` | Cost / Fatigue | < 20-30 |
| `avg_time_to_decide` | Speed | < 5 min для standard |
| `correction_rate` | Trust calibration | < 15% |
| `unauthorized_attempt_rate` | Authority | 0% |
| `auto_execute_rate` | Speed / Cost balance | 60-80% для LOW-risk |

> **Принцип:** Вихід за межі балансу призводить або до надмірного втручання (сповільнення), або до "approval theatre" (формальний контроль без реальної перевірки).

---

## 12. Upstream Design — Контроль "вгору за течією"

Ефективний контроль починається **до генерації результату**, а не після.

### Архітектурне рішення, а не крок workflow

| Підхід | Традиційний | IMCP |
|--------|-------------|------|
| Місце контролю | Кнопка "схвалити" в кінці | Вбудовано в логіку системи |
| Коли втручається людина | Коли контекст вже втрачено | На етапі формування рішення |
| Роль експерта | Перевіряє вихідні дані | Формує правила та межі |

### Контекстне заземлення

Людина визначає **межі та політики** заздалегідь:
- "Переглянути постачальників згідно з політикою 2024 року"
- "Для небезпечних вантажів — завжди повна перевірка"
- "При dims mismatch > 20% — обов'язковий approval"

Це запобігає:
- "галюцинаціям" AI через відсутність контексту
- дрейфу моделі від бізнес-правил
- прийняттю рішень без достатньої інформації

### Участь експертів у проєктуванні

SME (Subject Matter Experts) **закладають нюанси** в логіку агента:
- бізнес-правила для кожного case_type
- етичні кордони та non-negotiable rules
- порогові значення для ризиків
- exceptions та edge cases

> **Принцип:** Людське судження формує архітектуру, а не тільки кінцеві рішення.

---

## 13. Final Statement

IMCP — це не про заміну людей.  
Це про те, щоб **дозволити людям працювати на піку своїх можливостей**,  
делегуючи машині швидкість, масштаб і рутину.

> **ШІ генерує. Людина вирішує. Відповідальність залишається людською.**

IMCP реалізує **HITL 2.0** — систему, де:
- людина не просто "запобіжник", а **вчитель** для AI
- кожне виправлення стає **сигналом для покращення**
- контроль вбудований в **архітектуру**, а не в кінець процесу
- система **адаптується** до контексту і рівня впевненості

Це і є наш спільний mental model.

---

**Наступний документ:** [01_architecture_overview.md](./01_architecture_overview.md) — як ця ментальна модель реалізована в архітектурі.